# Emotion Expression Benchmarking Guide

## Overview

The emotion benchmarking system provides comprehensive analysis of emotional expressions generated by IndexTTS2 API. It systematically tests different emotions, intensities, and combinations, then analyzes the audio features to measure emotional expressiveness.

## Features

### 1. Systematic Emotion Testing
- **8 base emotions**: happy, sad, angry, surprised, calm, afraid, disgusted, melancholic
- **3 intensity levels** per emotion: low (0.3), medium (0.6), high (0.9)
- **Mixed emotions**: Combinations of multiple emotions
- **Baseline**: Natural emotion (no control) for comparison

### 2. Comprehensive Audio Analysis

#### Pitch Features
- **Pitch mean**: Average fundamental frequency (F0)
- **Pitch std**: Standard deviation (variability)
- **Pitch range**: Min to max pitch span
- **Pitch variation**: Coefficient of variation (std/mean)
- **Voiced ratio**: Percentage of voiced segments

#### Energy Features
- **Energy mean**: Average RMS energy
- **Energy std**: Energy variability
- **Energy range**: Min to max energy span
- **Energy dynamics**: Coefficient of variation

#### Tempo/Rhythm Features
- **Tempo (BPM)**: Beats per minute
- **Beat count**: Number of detected beats
- **Beats per second**: Speech rhythm rate

#### Spectral Features
- **Spectral centroid**: Brightness/timbre
- **Spectral rolloff**: Frequency content distribution
- **MFCCs**: Mel-frequency cepstral coefficients (timbre)

#### Prosody Features
- **Zero crossing rate**: Speech vs silence patterns
- **Speech rate**: Approximate speaking rate

### 3. Expressiveness Scoring

The system calculates an **expressiveness score** (0-100) that combines:
- Pitch variation (30%)
- Energy dynamics (25%)
- Pitch range (20%)
- Energy range (15%)
- Spectral variation (10%)

Higher scores indicate more emotionally expressive speech.

### 4. Baseline Comparison

Each emotion is compared against the natural (baseline) version:
- Pitch differences (mean, std, range, variation)
- Energy differences (mean, std, dynamics)
- Expressiveness difference
- Whether more or less expressive than baseline

## Usage

### Basic Usage

```bash
python3 benchmark_emotions.py \
    --voice "path/to/voice_reference.wav" \
    --text "This is a test sentence." \
    --text "Another test sentence." \
    --output-dir test_outputs/emotion_benchmark
```

### Example

```bash
python3 benchmark_emotions.py \
    --voice "youtube_audio_hh-VQ_T1Y9E/WHOP Unlocked ðŸš€ Inside the Platform Powering Online Businesses_segment_001.wav" \
    --text "This is a neutral statement for baseline comparison." \
    --text "I'm feeling extremely happy and excited about this!" \
    --text "This situation makes me feel very sad and disappointed." \
    --output-dir test_outputs/emotion_benchmark
```

## Output

### Generated Files

All generated audio files are saved to the output directory:
- `text_01_natural.wav` - Baseline (no emotion control)
- `text_01_happy_low.wav` - Happy, low intensity
- `text_01_happy_medium.wav` - Happy, medium intensity
- `text_01_happy_high.wav` - Happy, high intensity
- ... (and so on for all emotions and intensities)

### Benchmark Report

A comprehensive JSON report is generated: `benchmark_report.json`

#### Report Structure

```json
{
  "timestamp": "2025-12-26T16:00:00",
  "total_samples": 75,
  "emotions_tested": {
    "natural": {
      "count": 3,
      "avg_expressiveness": 45.2,
      "avg_pitch_variation": 0.15,
      "avg_energy_dynamics": 0.32
    },
    "happy_high": {
      "count": 3,
      "avg_expressiveness": 68.5,
      "avg_pitch_variation": 0.28,
      "avg_energy_dynamics": 0.45
    }
  },
  "statistics": {
    "avg_expressiveness": 52.3,
    "std_expressiveness": 12.5,
    "min_expressiveness": 35.1,
    "max_expressiveness": 78.2
  },
  "rankings": {
    "most_expressive": ["happy_high", "surprised_high", "angry_high"],
    "least_expressive": ["calm_low", "natural", "calm_medium"]
  },
  "detailed_results": [
    {
      "text_number": 1,
      "emotion": "happy_high",
      "expressiveness_score": 68.5,
      "pitch_variation": 0.28,
      "energy_dynamics": 0.45,
      "comparison": {
        "pitch": {...},
        "energy": {...},
        "expressiveness_diff": 23.3,
        "more_expressive": true
      }
    }
  ]
}
```

## Interpreting Results

### Expressiveness Scores

- **0-30**: Low expressiveness (monotone, flat)
- **30-50**: Moderate expressiveness (natural speech)
- **50-70**: High expressiveness (emotionally expressive)
- **70-100**: Very high expressiveness (highly dramatic)

### Pitch Variation

- **Low (< 0.1)**: Monotone, little pitch variation
- **Medium (0.1-0.2)**: Natural pitch variation
- **High (> 0.2)**: Dramatic pitch variation

### Energy Dynamics

- **Low (< 0.2)**: Flat energy, little variation
- **Medium (0.2-0.4)**: Natural energy variation
- **High (> 0.4)**: Dramatic energy variation

### Comparison Metrics

- **Positive expressiveness_diff**: More expressive than baseline
- **Negative expressiveness_diff**: Less expressive than baseline
- **Pitch differences**: How pitch changes from baseline
- **Energy differences**: How energy changes from baseline

## Best Practices

1. **Use multiple texts**: Test with different sentence types (statements, questions, exclamations)
2. **Compare intensities**: See how intensity affects expressiveness
3. **Check rankings**: Use the rankings to find most/least expressive emotions
4. **Review comparisons**: Compare against baseline to understand emotion effects
5. **Test mixed emotions**: Try combinations for nuanced expressions

## Troubleshooting

### "Module not found" errors
```bash
pip install librosa numpy soundfile
```

### API quota errors
- Set `HF_TOKEN` environment variable
- Wait for quota to reset
- Use fewer configurations (modify `generate_emotion_configs()`)

### Feature extraction errors
- Ensure audio files are valid WAV files
- Check that librosa can load the files
- Verify audio has sufficient duration (> 1 second)

## Advanced Usage

### Custom Emotion Configurations

Modify `generate_emotion_configs()` in `benchmark_emotions.py` to:
- Add custom emotions
- Adjust intensity levels
- Create new emotion combinations

### Custom Analysis

Extend `extract_emotion_features()` to add:
- Additional spectral features
- Formant analysis
- Voice quality metrics
- Perceptual features

## Performance

- **Generation time**: ~15-30 seconds per sample (API dependent)
- **Analysis time**: ~1-2 seconds per sample
- **Total time**: ~20-35 seconds per sample

For 3 texts Ã— 25 configurations = 75 samples:
- **Total time**: ~25-45 minutes

## Next Steps

1. Run benchmark with your voice reference
2. Review the JSON report
3. Listen to top/bottom ranked emotions
4. Use insights to optimize emotion parameters
5. Create custom emotion presets based on results

